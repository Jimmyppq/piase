[DURATION]
#Directorio dónde escribirá el log principal del script
LogFilePath= logs/log_13042024.log
#Directorio del log del script que cuenta las lineas escritas por cada 2 archivos
LogWriteFilePath=./logs/log_write_13042024.log
#Directorio del log que cuenta la velocidad de lecutra de cada archivo
LogReadFilePath=./logs/log_read_13042024.log
#Ubicación de los archivos que procesará (logs del cliente)
InputPath=./data
#Patrón de búsqueda de los archivos del directorio seteado en la variable $InputPath.
FilePattern=test*.log
#Ubicación del archivo resultante de la ejecución
OutputFilePath=./output/result_13042024.csv
# Ubicación del archivo que contiene los colectores
fileCollectors = ./config/collectors.json
[CONSOLIDATE]
#directorio dónd estarán los archivos a procesar
InputDirectory = ./output/
#Patrón de búsqueda de archivos dentro del directorio InputDirectory.
FilePattern = result_13042024.csv
#Directorio dónde ubicará los logs
LogDirectory = ./logs/
#Nombre del log
logName = log_consolidate_13042024.log
#Ubicación del archivo resultante
#OutputResult = /mnt/NAS/BANORTE/265_LATSUP-3186_Recolección Logs peak Transaccional Octubre 2023/2023-10-19 01 L01/SDP_depurados_DR/Outputs/Consolidate/29-DIC/v1-result_29122023_consolidate_Mnew.csv
OutputResult = ./output/result_consolidate_11042024.csv
#Intervalo para escribir transacciones en los logs
LogInterval = 20
#bloque de procesamiento del archivo
Chunk_size_write = 10000000


