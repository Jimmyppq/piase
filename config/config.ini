[DURATION]
#Ubicación de los archivos que consumirá (logs del cliente)
InputPath=./data/
FilePattern=*.log
#Ubicación del archivo resultante de la ejecución
OutputFilePath=./output/resultWindowSizing.csv
#Define si se escribiran las transacciones que se descartan True False. por defecto False
writeDiscarded = True
#Archivo dónde se almacenaran las transacciones descartadas
LogDiscardedTrx =./logs/log_discardTrx.log
#establece el bloque de registros del diccionario en memoria que se utilizará para realizar escrituras en bloque a disco
Chunk_size_write = 5
#establece cada cuantos archivos se hace commit de las transacciones para empezar a procesar el resultado definitivo
#una transacción que este en un commit diferente es considerada como una transacción nueva. Se recomienda un límite alto pero que no supere
#la memoria del servidor, por ejemplo 90
Chunk_size_write_files = 3
#Directorio dónde escribirá el log principal del script
LogFilePath=./logs/log_duration.log
#Directorio del log que registra la cantidad de transacciones que encuentra en cada archivo
LogWriteFilePath=./logs/log_write.log
#Directorio del log que cuenta la velocidad de lecutra de cada archivo
LogReadFilePath=./logs/log_read.log
# Lista de valores válidos para action
valid_actions = MNEWTRANS,NEWTRANS,SEND
# Lista de valores válidos para subcomponent
valid_subcomponents = FailOverManager,ServiceCenterOu


[CONSOLIDATE]
#directorio dónde estarán el archivo duration a procesar
#InputDirectory = /mnt/NAS/BANORTE/288_LATSUP-3486-Recoleccion Log analisis transaccional 15 Febrero 2024/2024-02-19 01 L01/Depurado/TDT/duration
InputDirectory= ./output
#Patrón de búsqueda de archivo del duration dentro del directorio InputDirectory.
FilePattern = resultWindowSizing.csv
#Directorio dónde ubicará los logs
LogDirectory = ./logs/
#Nombre del log
logName = log_consolidate.log
#Ubicación del archivo resultante
#OutputResult = /mnt/NAS/BANORTE/265_LATSUP-3186_Recolección Logs peak Transaccional Octubre 2023/2023-10-19 01 L01/SDP_depurados_DR/Outputs/Consolidate/29-DIC/v1-result_29122023_consolidate_Mnew.csv
OutputResult = ./output/result_consolidate1.csv
OutputInots = ./output/result_consolidate_inot.csv
#Intervalo para escribir transacciones en los logs
LogInterval = 10000
#bloque de procesamiento del archivo
Chunk_size_write = 10000000

[TRANSACTION_PROCESSOR]
# Archivo de entrada
InputFile=./output/result_consolidate_07052024.csv
# Archivo de salida
OutputFile=./output/result_transactionP.csv
# Tamaño del bloque
BlockSize=2
# Directorio del log principal del script
LogFilePath=./logs/log_transaction_processor.log
# Directorio del log que registra la cantidad de transacciones que encuentra en cada archivo
LogWriteFilePath=./logs/log_write_transaction_processor.log

[DATABASE]
host=localhost
database=qosmetricsdb
user=appQosMetrics
password=qosMetr!cs2024

[PROCESS]
# Lista de valores válidos para action
valid_actions = MNEWTRANS,NEWTRANS,SEND
# Lista de valores válidos para subcomponent
valid_subcomponents = FailOverManager,ServiceCenterOu
#archivo de log del proceso de lectura de logs y escritura a la BD
LogFilePathReadLogs=./logs/log_database_processlogs.log
#archivo de log del proceso de lectura de bd y escritura a archivo final
LogFilePath=./logs/log_database.log
LogWriteFilePath = ./logs/log_write_process.log
chunk_commit_databse = 20000
#tamaño del bloque a leer de la base de datos
size_process = 10000
#Ubicación de los archivos que consumirá (logs del cliente)
InputPath=./data
FilePattern=*.log
Chunk_size_write = 100
OutputFilePath =  ./output/result_processDB_1551.csv